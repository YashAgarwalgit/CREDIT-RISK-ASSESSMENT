{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76830da-be31-4fc8-84a7-386ef67013c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Test Cell 1 ---\n",
      "Variable 1 is: 'Hello from Cell 1'\n",
      "Variable 2 is: 12345\n",
      "‚úÖ Test Cell 1 Finished. Variables have been created.\n"
     ]
    }
   ],
   "source": [
    "# Test Cell 1\n",
    "print(\"--- Running Test Cell 1 ---\")\n",
    "\n",
    "my_variable_1 = \"Hello from Cell 1\"\n",
    "my_variable_2 = 12345\n",
    "\n",
    "print(f\"Variable 1 is: '{my_variable_1}'\")\n",
    "print(f\"Variable 2 is: {my_variable_2}\")\n",
    "print(\"‚úÖ Test Cell 1 Finished. Variables have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571bbde5-13da-4512-aef5-d21fdcfd1c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Test Cell 2 ---\n",
      "Attempting to access variables from Cell 1...\n",
      "SUCCESS! Found variable 1: 'Hello from Cell 1'\n",
      "SUCCESS! Found variable 2: 12345\n",
      "\n",
      "‚úÖ --- Diagnosis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Test Cell 2\n",
    "print(\"--- Running Test Cell 2 ---\")\n",
    "print(\"Attempting to access variables from Cell 1...\")\n",
    "\n",
    "try:\n",
    "    # Check if the variables from the previous cell still exist\n",
    "    if 'my_variable_1' in locals() or 'my_variable_1' in globals():\n",
    "        print(f\"SUCCESS! Found variable 1: '{my_variable_1}'\")\n",
    "    else:\n",
    "        print(\"FAILURE! Could not find variable 1.\")\n",
    "\n",
    "    if 'my_variable_2' in locals() or 'my_variable_2' in globals():\n",
    "         print(f\"SUCCESS! Found variable 2: {my_variable_2}\")\n",
    "    else:\n",
    "         print(\"FAILURE! Could not find variable 2.\")\n",
    "\n",
    "    print(\"\\n‚úÖ --- Diagnosis Complete ---\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\n‚ùå‚ùå‚ùå CRITICAL ERROR: A NameError occurred. The notebook is definitely losing its memory between cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46640132-8efc-46b7-a01a-8e4d5a684fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell Execution Started ---\n",
      "‚úÖ Configuration object created successfully.\n",
      "\n",
      "--- Attempting to Generate Data ---\n",
      "‚úÖ SyntheticSMEDataGenerator initialized for 5000 samples.\n",
      "‚öôÔ∏è Generating synthetic data...\n",
      "‚úÖ Synthetic dataset generated with 5000 records.\n",
      "\n",
      "--- Data Generation Cell Complete. `raw_df` variable is created. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sme_id</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>business_location_zone</th>\n",
       "      <th>avg_monthly_inflow</th>\n",
       "      <th>balance_volatility</th>\n",
       "      <th>num_late_utility_payments_last_year</th>\n",
       "      <th>website_quality_score</th>\n",
       "      <th>online_review_score</th>\n",
       "      <th>founder_bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SME_1000</td>\n",
       "      <td>0</td>\n",
       "      <td>Zone A (Urban)</td>\n",
       "      <td>43865.642581</td>\n",
       "      <td>2382.378205</td>\n",
       "      <td>4</td>\n",
       "      <td>5.198247</td>\n",
       "      <td>2.508531</td>\n",
       "      <td>A driven entrepreneur with a solid plan, build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SME_1001</td>\n",
       "      <td>1</td>\n",
       "      <td>Zone A (Urban)</td>\n",
       "      <td>26076.910921</td>\n",
       "      <td>3842.275860</td>\n",
       "      <td>5</td>\n",
       "      <td>0.117698</td>\n",
       "      <td>1.044701</td>\n",
       "      <td>A passionate operational hurdles. Currently na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SME_1002</td>\n",
       "      <td>0</td>\n",
       "      <td>Zone B (Suburban)</td>\n",
       "      <td>48337.212965</td>\n",
       "      <td>2217.426395</td>\n",
       "      <td>1</td>\n",
       "      <td>6.315600</td>\n",
       "      <td>4.134901</td>\n",
       "      <td>An successful exit leader with a innovative. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SME_1003</td>\n",
       "      <td>0</td>\n",
       "      <td>Zone B (Suburban)</td>\n",
       "      <td>37014.762804</td>\n",
       "      <td>2743.876049</td>\n",
       "      <td>0</td>\n",
       "      <td>5.570630</td>\n",
       "      <td>3.441893</td>\n",
       "      <td>An innovative leader with a strategic. Focused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SME_1004</td>\n",
       "      <td>1</td>\n",
       "      <td>Zone A (Urban)</td>\n",
       "      <td>13324.801085</td>\n",
       "      <td>4523.096012</td>\n",
       "      <td>5</td>\n",
       "      <td>3.186333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>A passionate learning curve. Currently navigat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sme_id  credit_default business_location_zone  avg_monthly_inflow  \\\n",
       "0  SME_1000               0         Zone A (Urban)        43865.642581   \n",
       "1  SME_1001               1         Zone A (Urban)        26076.910921   \n",
       "2  SME_1002               0      Zone B (Suburban)        48337.212965   \n",
       "3  SME_1003               0      Zone B (Suburban)        37014.762804   \n",
       "4  SME_1004               1         Zone A (Urban)        13324.801085   \n",
       "\n",
       "   balance_volatility  num_late_utility_payments_last_year  \\\n",
       "0         2382.378205                                    4   \n",
       "1         3842.275860                                    5   \n",
       "2         2217.426395                                    1   \n",
       "3         2743.876049                                    0   \n",
       "4         4523.096012                                    5   \n",
       "\n",
       "   website_quality_score  online_review_score  \\\n",
       "0               5.198247             2.508531   \n",
       "1               0.117698             1.044701   \n",
       "2               6.315600             4.134901   \n",
       "3               5.570630             3.441893   \n",
       "4               3.186333             1.000000   \n",
       "\n",
       "                                         founder_bio  \n",
       "0  A driven entrepreneur with a solid plan, build...  \n",
       "1  A passionate operational hurdles. Currently na...  \n",
       "2  An successful exit leader with a innovative. F...  \n",
       "3  An innovative leader with a strategic. Focused...  \n",
       "4  A passionate learning curve. Currently navigat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- All necessary imports for this step ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "print(\"--- Cell Execution Started ---\")\n",
    "\n",
    "# --- Step 1: Define the Configuration Class ---\n",
    "class Configuration:\n",
    "    \"\"\"A centralized class to hold all project configurations.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.N_SAMPLES: int = 5000\n",
    "        self.RANDOM_STATE: int = 42\n",
    "        self.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Step 2: Instantiate the Configuration ---\n",
    "try:\n",
    "    CONFIG = Configuration()\n",
    "    print(\"‚úÖ Configuration object created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating Configuration object: {e}\")\n",
    "\n",
    "# --- Step 3: Define the Data Generator Class ---\n",
    "class SyntheticSMEDataGenerator:\n",
    "    \"\"\"Generates a high-fidelity synthetic dataset for SME credit risk assessment.\"\"\"\n",
    "    def __init__(self, config: Configuration):\n",
    "        self.config = config\n",
    "        self.rng = np.random.default_rng(self.config.RANDOM_STATE)\n",
    "        self.n_samples = self.config.N_SAMPLES\n",
    "        print(f\"‚úÖ SyntheticSMEDataGenerator initialized for {self.n_samples} samples.\")\n",
    "\n",
    "    def _generate_base_profile(self):\n",
    "        \"\"\"Generates the base probability of default.\"\"\"\n",
    "        self.base_business_quality = self.rng.normal(0.5, 0.2, self.n_samples)\n",
    "        self.base_business_quality = np.clip(self.base_business_quality, 0, 1)\n",
    "        self.location_zone = self.rng.choice(['Zone A (Urban)', 'Zone B (Suburban)', 'Zone C (Rural)'], self.n_samples, p=[0.5, 0.3, 0.2])\n",
    "        location_bias = {'Zone A (Urban)': 0.0, 'Zone B (Suburban)': -0.05, 'Zone C (Rural)': 0.1}\n",
    "        self.location_adjustment = np.array([location_bias[zone] for zone in self.location_zone])\n",
    "        prob_default = 1 / (1 + np.exp(-((0.5 - self.base_business_quality) * 5 + self.location_adjustment * 2)))\n",
    "        self.credit_default = self.rng.binomial(1, np.clip(prob_default, 0.01, 0.99))\n",
    "\n",
    "    def _generate_features(self):\n",
    "        \"\"\"Generates all feature categories.\"\"\"\n",
    "        self.avg_monthly_inflow = (self.base_business_quality + self.rng.normal(0, 0.1, self.n_samples)) * 50000 + 10000\n",
    "        self.balance_volatility = (1 - self.base_business_quality + self.rng.normal(0, 0.1, self.n_samples)) * 5000 + 500\n",
    "        self.num_late_utility_payments_last_year = self.rng.poisson((1 - self.base_business_quality) * 5)\n",
    "        self.website_quality_score = np.clip(self.base_business_quality + self.rng.normal(0, 0.15, self.n_samples), 0, 1) * 10\n",
    "        self.online_review_score = np.clip(self.base_business_quality * 5 + self.rng.normal(0, 0.5, self.n_samples), 1, 5)\n",
    "        positive_keywords = [\"experienced\", \"proven track record\", \"innovative\", \"strategic\", \"successful exit\", \"industry veteran\"]\n",
    "        negative_keywords = [\"first-time founder\", \"learning curve\", \"market challenges\", \"pivoting\", \"operational hurdles\", \"bootstrap\"]\n",
    "        self.founder_bios = []\n",
    "        for quality in self.base_business_quality:\n",
    "            if quality > 0.6:\n",
    "                text = f\"An {self.rng.choice(positive_keywords)} leader with a {self.rng.choice(positive_keywords)}. Focused on scalable solutions and sustainable growth.\"\n",
    "            elif quality < 0.4:\n",
    "                text = f\"A passionate {self.rng.choice(negative_keywords)}. Currently navigating {self.rng.choice(negative_keywords)} and adapting the business model.\"\n",
    "            else:\n",
    "                text = \"A driven entrepreneur with a solid plan, building on previous experience to secure a strong product-market fit.\"\n",
    "            self.founder_bios.append(text)\n",
    "\n",
    "    def generate_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"Generates and returns the complete dataset.\"\"\"\n",
    "        print(\"‚öôÔ∏è Generating synthetic data...\")\n",
    "        self._generate_base_profile()\n",
    "        self._generate_features()\n",
    "        df = pd.DataFrame({\n",
    "            'sme_id': [f\"SME_{1000+i}\" for i in range(self.n_samples)],\n",
    "            'credit_default': self.credit_default,\n",
    "            'business_location_zone': self.location_zone,\n",
    "            'avg_monthly_inflow': self.avg_monthly_inflow,\n",
    "            'balance_volatility': self.balance_volatility,\n",
    "            'num_late_utility_payments_last_year': self.num_late_utility_payments_last_year,\n",
    "            'website_quality_score': self.website_quality_score,\n",
    "            'online_review_score': self.online_review_score,\n",
    "            'founder_bio': self.founder_bios\n",
    "        })\n",
    "        print(f\"‚úÖ Synthetic dataset generated with {len(df)} records.\")\n",
    "        return df\n",
    "\n",
    "# --- Step 4: Execute the Data Generation ---\n",
    "try:\n",
    "    print(\"\\n--- Attempting to Generate Data ---\")\n",
    "    data_generator = SyntheticSMEDataGenerator(CONFIG)\n",
    "    raw_df = data_generator.generate_dataset()\n",
    "    print(\"\\n--- Data Generation Cell Complete. `raw_df` variable is created. ---\")\n",
    "    # Display the head of the created dataframe to confirm success\n",
    "    display(raw_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå‚ùå‚ùå An error occurred during execution: {e}\")\n",
    "\n",
    "# --- Step 5: Clean Memory ---\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733259e2-19ef-4ee4-a119-287910638f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 2: Feature Engineering ---\n",
      "FeatureEngineer initialized.\n",
      "Loading SentenceTransformer model ('all-MiniLM-L6-v2')... This may take a minute.\n",
      "‚úÖ NLP models loaded successfully.\n",
      "\n",
      "--- Starting Feature Engineering Pipeline ---\n",
      "‚öôÔ∏è Engineering NLP features from 'founder_bio'...\n",
      "üß† Generating semantic embeddings... (This is the longest step in this cell)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39798e1dc0c446e5ae95dd2c78f05294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- All necessary imports for this step ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "print(\"--- Cell 2: Feature Engineering ---\")\n",
    "\n",
    "# --- Step 1: Define the Configuration and Helper functions ---\n",
    "# We redefine these here to make the cell completely self-contained.\n",
    "class Configuration:\n",
    "    \"\"\"A centralized class to hold all project configurations.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.ST_MODEL_NAME: str = 'all-MiniLM-L6-v2'\n",
    "        self.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def download_nltk_data():\n",
    "    \"\"\"Downloads required NLTK data if not already present.\"\"\"\n",
    "    required = [('sentiment', 'vader_lexicon'), ('corpora', 'stopwords'), ('tokenizers', 'punkt')]\n",
    "    for package_id, resource in required:\n",
    "        try:\n",
    "            nltk.data.find(f\"{package_id}/{resource}.zip\")\n",
    "        except LookupError:\n",
    "            print(f\"‚¨áÔ∏è Downloading NLTK data: {resource}...\")\n",
    "            nltk.download(resource.split('.')[0], quiet=True)\n",
    "\n",
    "CONFIG = Configuration()\n",
    "download_nltk_data()\n",
    "\n",
    "# --- Step 2: Define the Feature Engineer Class ---\n",
    "class FeatureEngineer:\n",
    "    \"\"\"Handles all feature engineering tasks in a structured pipeline.\"\"\"\n",
    "    def __init__(self, config: Configuration):\n",
    "        self.config = config\n",
    "        print(\"FeatureEngineer initialized.\")\n",
    "        try:\n",
    "            print(f\"Loading SentenceTransformer model ('{self.config.ST_MODEL_NAME}')... This may take a minute.\")\n",
    "            self.st_model = SentenceTransformer(self.config.ST_MODEL_NAME, device=self.config.DEVICE)\n",
    "            self.sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "            print(\"‚úÖ NLP models loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load NLP models: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(nopython=True)\n",
    "    def _calculate_stability_score(inflows, volatilities):\n",
    "        \"\"\"A Numba-accelerated function for a custom stability score.\"\"\"\n",
    "        scores = np.zeros(len(inflows))\n",
    "        for i in range(len(inflows)):\n",
    "            ratio = inflows[i] / (volatilities[i] + 1e-6)\n",
    "            scores[i] = 1 - np.exp(-ratio / 100) # Score between 0 and 1\n",
    "        return scores\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Applies all feature engineering steps.\"\"\"\n",
    "        print(\"\\n--- Starting Feature Engineering Pipeline ---\")\n",
    "        df_featured = df.copy()\n",
    "\n",
    "        # NLP Features\n",
    "        print(\"‚öôÔ∏è Engineering NLP features from 'founder_bio'...\")\n",
    "        df_featured['founder_sentiment'] = df_featured['founder_bio'].apply(lambda x: self.sentiment_analyzer.polarity_scores(x)['compound'])\n",
    "        \n",
    "        print(\"üß† Generating semantic embeddings... (This is the longest step in this cell)\")\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.st_model.encode(df_featured['founder_bio'].tolist(), show_progress_bar=True, convert_to_tensor=True, device=self.config.DEVICE)\n",
    "        embedding_df = pd.DataFrame(embeddings.cpu().numpy(), index=df_featured.index)\n",
    "        embedding_df.columns = [f'bio_emb_{i}' for i in range(embedding_df.shape[1])]\n",
    "        df_featured = pd.concat([df_featured, embedding_df], axis=1)\n",
    "        print(f\"‚úÖ Generated {embedding_df.shape[1]}-dimensional embeddings.\")\n",
    "\n",
    "        # Numba-accelerated Feature\n",
    "        print(\"üöÄ Applying Numba-accelerated function...\")\n",
    "        df_featured['financial_stability_score'] = self._calculate_stability_score(\n",
    "            df_featured['avg_monthly_inflow'].to_numpy(),\n",
    "            df_featured['balance_volatility'].to_numpy()\n",
    "        )\n",
    "        \n",
    "        # Final cleanup\n",
    "        df_featured = df_featured.drop(columns=['founder_bio'])\n",
    "        print(\"‚úÖ Feature Engineering Complete.\")\n",
    "        return df_featured\n",
    "\n",
    "# --- Step 3: Execute the Feature Engineering ---\n",
    "try:\n",
    "    # This assumes 'raw_df' was created successfully in the previous cell.\n",
    "    if 'raw_df' in locals():\n",
    "        feature_engineer = FeatureEngineer(CONFIG)\n",
    "        featured_df = feature_engineer.transform(raw_df)\n",
    "        print(\"\\n--- Feature Engineering Cell Complete. `featured_df` variable is created. ---\")\n",
    "        display(featured_df.head())\n",
    "    else:\n",
    "        print(\"‚ùå ERROR: The `raw_df` DataFrame was not found. Please run the data generation cell first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå‚ùå‚ùå An error occurred during feature engineering: {e}\")\n",
    "\n",
    "# --- Step 4: Clean Memory ---\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3d9ba-ffac-495e-b7c7-7d480e887c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- All necessary imports for this step ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import gc\n",
    "\n",
    "print(\"--- Cell 3: Model Training ---\")\n",
    "\n",
    "# --- Step 1: Define the Configuration ---\n",
    "class Configuration:\n",
    "    \"\"\"A centralized class to hold all project configurations.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.RANDOM_STATE: int = 42\n",
    "        self.TEST_SIZE: float = 0.25\n",
    "        self.BATCH_SIZE: int = 128\n",
    "        self.EPOCHS: int = 20\n",
    "        self.LEARNING_RATE: float = 0.001\n",
    "        self.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONFIG = Configuration()\n",
    "\n",
    "# --- Step 2: Define the Model Trainer Class ---\n",
    "class ModelTrainer:\n",
    "    \"\"\"Manages the training and evaluation of all specified models.\"\"\"\n",
    "    def __init__(self, config: Configuration):\n",
    "        self.config = config\n",
    "        self.preprocessor = None\n",
    "        self.models = {}\n",
    "        self.metrics = {}\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = [None] * 4\n",
    "        print(\"ModelTrainer initialized.\")\n",
    "\n",
    "    class _SME_DNN(nn.Module):\n",
    "        \"\"\"Internal DNN model definition.\"\"\"\n",
    "        def __init__(self, input_size):\n",
    "            super().__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(input_size, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.4),\n",
    "                nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "                nn.Linear(128, 1), nn.Sigmoid()\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "\n",
    "    def _prepare_data(self, df: pd.DataFrame):\n",
    "        \"\"\"Splits and preprocesses the data.\"\"\"\n",
    "        print(\"\\n--- Preparing Data for Modeling ---\")\n",
    "        TARGET = 'credit_default'\n",
    "        features = [col for col in df.columns if col not in [TARGET, 'sme_id']]\n",
    "        X = df[features]\n",
    "        y = df[TARGET]\n",
    "\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            [('num', StandardScaler(), numerical_features),\n",
    "             ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=self.config.TEST_SIZE, random_state=self.config.RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        self.X_test_orig = self.X_test.copy()\n",
    "        \n",
    "        self.X_train = self.preprocessor.fit_transform(self.X_train)\n",
    "        self.X_test = self.preprocessor.transform(self.X_test)\n",
    "        print(\"‚úÖ Data prepared and preprocessed.\")\n",
    "\n",
    "    def _train_xgb(self):\n",
    "        \"\"\"Trains the XGBoost model.\"\"\"\n",
    "        print(\"\\n--- Training XGBoost Model ---\")\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic', eval_metric='logloss', use_label_encoder=False,\n",
    "            random_state=self.config.RANDOM_STATE, tree_method='gpu_hist'\n",
    "        )\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        self.models['XGBoost'] = model\n",
    "        print(\"‚úÖ XGBoost model trained.\")\n",
    "\n",
    "    def _train_dnn(self):\n",
    "        \"\"\"Trains the PyTorch DNN model.\"\"\"\n",
    "        print(\"\\n--- Training PyTorch DNN Model ---\")\n",
    "        X_train_t = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        y_train_t = torch.tensor(self.y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "        train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=self.config.BATCH_SIZE, shuffle=True)\n",
    "        model = self._SME_DNN(self.X_train.shape[1]).to(self.config.DEVICE)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.config.LEARNING_RATE)\n",
    "\n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            model.train()\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(self.config.DEVICE), batch_y.to(self.config.DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        self.models['PyTorch DNN'] = model\n",
    "        print(f\"‚úÖ PyTorch DNN model trained after {self.config.EPOCHS} epochs.\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluates all trained models.\"\"\"\n",
    "        print(\"\\n--- Evaluating Models ---\")\n",
    "        for name, model in self.models.items():\n",
    "            if name == 'XGBoost':\n",
    "                y_pred_proba = model.predict_proba(self.X_test)[:, 1]\n",
    "            elif name == 'PyTorch DNN':\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_test_t = torch.tensor(self.X_test, dtype=torch.float32).to(self.config.DEVICE)\n",
    "                    y_pred_proba = model(X_test_t).cpu().numpy().flatten()\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "            self.metrics[name] = {\n",
    "                'Accuracy': accuracy_score(self.y_test, y_pred),\n",
    "                'Precision': precision_score(self.y_test, y_pred),\n",
    "                'Recall': recall_score(self.y_test, y_pred),\n",
    "                'F1-Score': f1_score(self.y_test, y_pred),\n",
    "                'AUC-ROC': roc_auc_score(self.y_test, y_pred_proba),\n",
    "                'predictions_proba': y_pred_proba\n",
    "            }\n",
    "        print(\"‚úÖ Models evaluated.\")\n",
    "        \n",
    "    def run(self, df: pd.DataFrame):\n",
    "        \"\"\"Runs the entire training and evaluation pipeline.\"\"\"\n",
    "        self._prepare_data(df)\n",
    "        self._train_xgb()\n",
    "        self._train_dnn()\n",
    "        self.evaluate()\n",
    "        return self\n",
    "\n",
    "# --- Step 3: Execute the Model Training ---\n",
    "try:\n",
    "    if 'featured_df' in locals():\n",
    "        trainer = ModelTrainer(CONFIG).run(featured_df)\n",
    "        print(\"\\n--- Model Training Cell Complete. `trainer` object is created. ---\")\n",
    "    else:\n",
    "        print(\"‚ùå ERROR: The `featured_df` DataFrame was not found. Please run the feature engineering cell first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå‚ùå‚ùå An error occurred during model training: {e}\")\n",
    "\n",
    "# --- Step 4: Clean Memory ---\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e936ff-7a2d-491b-ba3c-1110f697aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- All necessary imports for this step ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, recall_score\n",
    "import shap\n",
    "\n",
    "print(\"--- Cell 4: Interactive Dashboard (Workaround Version) ---\")\n",
    "\n",
    "# --- Define the Dashboard Class (with FigureWidget replaced) ---\n",
    "class Dashboard:\n",
    "    \"\"\"Creates an interactive dashboard in Jupyter Notebook to explore the data, model performance, and interpretability results.\"\"\"\n",
    "    def __init__(self, raw_df: pd.DataFrame, trainer):\n",
    "        self.raw_df = raw_df\n",
    "        self.trainer = trainer\n",
    "        self.tab = widgets.Tab()\n",
    "        self._precompute_shap()\n",
    "        self.create_tabs()\n",
    "        print(\"‚úÖ Dashboard Initialized. Call the .show() method to display.\")\n",
    "\n",
    "    def _precompute_shap(self):\n",
    "        \"\"\"Calculates SHAP values once to make the dashboard faster.\"\"\"\n",
    "        print(\"üî¨ Pre-calculating SHAP values for dashboard... (This may take a moment)\")\n",
    "        model = self.trainer.models['XGBoost']\n",
    "        X_test_proc = self.trainer.preprocessor.transform(self.trainer.X_test_orig)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        self.shap_values = explainer(X_test_proc)\n",
    "        print(\"‚úÖ SHAP values calculated and stored.\")\n",
    "\n",
    "    def create_tabs(self):\n",
    "        \"\"\"Creates all the tabs for the dashboard.\"\"\"\n",
    "        children = [self._create_eda_tab(), self._create_performance_tab(), self._create_shap_tab(), self._create_fairness_tab()]\n",
    "        self.tab.children = children\n",
    "        titles = ['üìä EDA Explorer', 'üìà Model Performance', 'üî¨ Local Interpretability', '‚öñÔ∏è Fairness Audit']\n",
    "        for i, title in enumerate(titles):\n",
    "            self.tab.set_title(i, title)\n",
    "\n",
    "    def _create_eda_tab(self):\n",
    "        feature_dropdown = widgets.Dropdown(options=self.raw_df.columns.drop(['sme_id', 'founder_bio']), value='avg_monthly_inflow', description='Feature:', style={'description_width': 'initial'})\n",
    "        output = widgets.Output()\n",
    "        def on_feature_change(change):\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                feature = change['new']\n",
    "                fig = make_subplots(rows=1, cols=2, subplot_titles=(f'Distribution of {feature}', f'{feature} by Credit Default'))\n",
    "                if self.raw_df[feature].dtype == 'object':\n",
    "                    counts = self.raw_df.groupby([feature, 'credit_default']).size().reset_index(name='count')\n",
    "                    fig_cat = px.bar(counts, x=feature, y='count', color='credit_default', barmode='group')\n",
    "                    for trace in fig_cat.data: fig.add_trace(trace, row=1, col=1)\n",
    "                    for trace in fig_cat.data: fig.add_trace(trace, row=1, col=2)\n",
    "                else:\n",
    "                    fig_hist = px.histogram(self.raw_df, x=feature, color='credit_default', marginal='box', barmode='overlay', opacity=0.7)\n",
    "                    fig_box = px.box(self.raw_df, x='credit_default', y=feature, color='credit_default')\n",
    "                    for trace in fig_hist.data: fig.add_trace(trace, row=1, col=1)\n",
    "                    for trace in fig_box.data: fig.add_trace(trace, row=1, col=2)\n",
    "                fig.update_layout(height=400, title_text=f\"Analysis of '{feature}'\", legend_title_text='Default')\n",
    "                fig.show()\n",
    "        feature_dropdown.observe(on_feature_change, names='value')\n",
    "        on_feature_change({'new': feature_dropdown.value})\n",
    "        return widgets.VBox([feature_dropdown, output])\n",
    "\n",
    "    def _create_performance_tab(self):\n",
    "        metrics_df = pd.DataFrame(self.trainer.metrics).T.drop(columns=['predictions_proba']).round(4)\n",
    "        html = widgets.HTML(value=f\"<h3>Model Performance Metrics</h3>{metrics_df.to_html(classes='table table-striped')}\")\n",
    "        \n",
    "        # --- WORKAROUND --- Changed go.FigureWidget to the standard go.Figure\n",
    "        fig_roc = go.Figure()\n",
    "        \n",
    "        fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n",
    "        for name, metrics in self.trainer.metrics.items():\n",
    "            fpr, tpr, _ = roc_curve(self.trainer.y_test, metrics['predictions_proba'])\n",
    "            fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, name=f\"{name} (AUC={metrics['AUC-ROC']:.3f})\", mode='lines'))\n",
    "        fig_roc.update_layout(title='ROC Curves', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate', height=400)\n",
    "        \n",
    "        # We need to wrap the standard Figure in a FigureWidget to place it in the VBox\n",
    "        # but the error originates from creating the FigureWidget in the first place.\n",
    "        # Let's build the VBox with a placeholder and then display the figure separately if needed.\n",
    "        # A simpler approach is to just use an output widget for everything.\n",
    "        \n",
    "        performance_output = widgets.Output()\n",
    "        with performance_output:\n",
    "            display(html)\n",
    "            display(fig_roc) # Display the static figure\n",
    "\n",
    "            model_dropdown = widgets.Dropdown(options=list(self.trainer.models.keys()), description='Model:')\n",
    "            cm_output = widgets.Output()\n",
    "            def on_cm_model_change(change):\n",
    "                with cm_output:\n",
    "                    clear_output(wait=True)\n",
    "                    model_name = change['new']\n",
    "                    y_pred = (self.trainer.metrics[model_name]['predictions_proba'] > 0.5).astype(int)\n",
    "                    cm = confusion_matrix(self.trainer.y_test, y_pred)\n",
    "                    fig_cm = px.imshow(cm, text_auto=True, labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"), x=['No Default', 'Default'], y=['No Default', 'Default'], color_continuous_scale='Blues')\n",
    "                    fig_cm.update_layout(title=f'Confusion Matrix for {model_name}', height=400)\n",
    "                    fig_cm.show()\n",
    "            model_dropdown.observe(on_cm_model_change, names='value')\n",
    "            display(widgets.HBox([model_dropdown, cm_output]))\n",
    "            on_cm_model_change({'new': model_dropdown.value})\n",
    "\n",
    "        return performance_output\n",
    "\n",
    "\n",
    "    def _create_shap_tab(self):\n",
    "        sme_dropdown = widgets.Dropdown(options=self.trainer.X_test_orig.index, description='Select SME ID:', layout=Layout(width='50%'))\n",
    "        output = widgets.Output()\n",
    "        def on_sme_select(change):\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                sme_index = change['new']\n",
    "                loc_index = self.trainer.X_test_orig.index.get_loc(sme_index)\n",
    "                sme_info = self.raw_df.loc[sme_index]\n",
    "                info_html = f\"<b>SME ID:</b> {sme_info.name}<br><b>Founder Bio:</b> \\\"{sme_info.founder_bio}\\\"<br><b>Actual Outcome:</b> {'Default' if self.trainer.y_test.loc[sme_index] == 1 else 'No Default'}<br><b>Predicted Risk Score:</b> {self.trainer.metrics['XGBoost']['predictions_proba'][loc_index]:.3f}\"\n",
    "                display(widgets.HTML(value=info_html))\n",
    "                feature_names = self.trainer.preprocessor.get_feature_names_out().tolist()\n",
    "                clean_names = [name.split('__')[-1] for name in feature_names]\n",
    "                base_value = self.shap_values.base_values[loc_index]\n",
    "                shap_plot_values = self.shap_values.values[loc_index]\n",
    "                top_features_indices = np.argsort(np.abs(shap_plot_values))[-10:]\n",
    "                fig = go.Figure(go.Waterfall(\n",
    "                    orientation=\"h\", x=np.append(shap_plot_values[top_features_indices], shap_plot_values.sum()),\n",
    "                    y = np.append([clean_names[i] for i in top_features_indices], ['Final Prediction']),\n",
    "                    measure = np.append([\"relative\"] * len(top_features_indices), [\"total\"]),\n",
    "                    base = base_value\n",
    "                ))\n",
    "                fig.update_layout(title=f\"Local Interpretation for {sme_info.name}\", height=500, yaxis=dict(autorange=\"reversed\"))\n",
    "                fig.show()\n",
    "        sme_dropdown.observe(on_sme_select, names='value')\n",
    "        on_sme_select({'new': sme_dropdown.value})\n",
    "        return widgets.VBox([sme_dropdown, output])\n",
    "\n",
    "    def _create_fairness_tab(self):\n",
    "        attribute_dropdown = widgets.Dropdown(options=['business_location_zone'], description='Protected Attribute:')\n",
    "        output = widgets.Output()\n",
    "        def on_attribute_change(change):\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                attribute = change['new']\n",
    "                audit_df = self.trainer.X_test_orig.copy()\n",
    "                audit_df['true_default'] = self.trainer.y_test\n",
    "                audit_df['predicted_default'] = (self.trainer.metrics['XGBoost']['predictions_proba'] > 0.5).astype(int)\n",
    "                results = {group: recall_score(subgroup['true_default'], subgroup['predicted_default']) for group, subgroup in audit_df.groupby(attribute) if len(subgroup['true_default'].unique()) > 1}\n",
    "                results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Recall (Equal Opportunity)'])\n",
    "                fig = px.bar(results_df, x=results_df.index, y='Recall (Equal Opportunity)', title=f'Fairness: Recall by {attribute}', text_auto='.3f', height=400)\n",
    "                fig.update_yaxes(range=[0, 1])\n",
    "                fig.show()\n",
    "        attribute_dropdown.observe(on_attribute_change, names='value')\n",
    "        on_attribute_change({'new': attribute_dropdown.value})\n",
    "        return widgets.VBox([attribute_dropdown, output])\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"Displays the entire dashboard.\"\"\"\n",
    "        display(self.tab)\n",
    "\n",
    "# --- Execute the Dashboard (Workaround Version) ---\n",
    "try:\n",
    "    dashboard = Dashboard(raw_df, trainer)\n",
    "    dashboard.show()\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå‚ùå‚ùå A NameError occurred: {e}. This confirms a variable was not created in a previous step.\")\n",
    "    print(\"Please use 'Kernel -> Restart & Run All' to ensure all steps run in order.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå‚ùå‚ùå An unexpected error occurred during dashboard creation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34747cdb-c52a-462c-8e98-40289e6c70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anywidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f28ca-6d8f-4ac7-917f-9e84c6f3b1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
